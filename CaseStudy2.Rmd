---
title: "CaseStudy2"
author: "Jason Mcdonald"
date: "2/10/2022"
output: html_document
---
[View the presentation video here](https://youtu.be/Ah3t4DHafc4)

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(kableExtra)
library(corrplot)
library(RColorBrewer)
library(caret)
#library(doParallel) #used code sample from https://topepo.github.io/caret/parallel-processing.html
#library(yardstick) #recommended during research at https://rpubs.com/jkylearmstrong/knn_w_caret
library(e1071)
library(ggplot2)
library(randomForest)
library(tidyverse)
library(dplyr)
library(regclass)
library(Cubist)
```

# Jason McDonald's Frito Lay Attrition Case Study

## Executive Summary
With current inflation data showing that inflation is outpacing wage growth drastically, employees are feeling an impact to their financial bottom line at home.  No longer can employees accept idle wage growth as such is accepting wage reductions when inflation is taken into account.

As a business, you must reward your employees financially with incentives that both satisfy their financial desires and address others they may have.

The question is, do we know what desires cause an employee to stay in a role?  Is it financial alone?  Is there some other factor which can cause an otherwise happy employee to leave?  Does this change over time, such as when inflation is growing at the rate it is now, in 2021 and 2022?

I've set out to provide you with insights using the data set you have provided, of 870 employees.


### Import the data
I was provided with 3 files containing employee data, 2 in Comma Separated Value format and 1 in Excel Workbook format which I then converted to CSV.  The first file contained data on 870 employees with a number of data points about each.  The second contained similar data points but no attrition data.  Finally, the third contained similar data points but no salary data.

Below, I will read in the data and begin to explore what columns and types of data exists in each.
```{r, Import Data}
trainData <- read.csv('CaseStudy2-data.csv')
attritionData <- read.csv('CaseStudy2CompSetNoAttrition.csv')
salaryData <- read.csv('CaseStudy2CompSetNoSalary.csv')
head(trainData)
```

### Look for missing data
I need to begin with a check to see if any data is missing and decide how to address that if so.
```{r}
which(is.na(trainData))
which(is.na(attritionData))
which(is.na(salaryData))
```
It looks like nothing is missing from the dataset, so I'll proceed to determine what I've been given and how I will need to clean the data to make it more suitable for predictive insights.

### Training Data Set
```{r, Training Variables}

#Display the columns in each data set in a table format
as.data.frame(lapply(trainData, class)) %>% t() %>% kable(bootstrap_options = "striped", full_width = F, position = "left") %>% kable_styling()
```

### No Attrition Data Set
```{r, No Attrition Variables}

#Display the columns in each data set in a table format
as.data.frame(lapply(attritionData, class)) %>% t() %>% kable() %>% kable_styling(bootstrap_options = "striped", full_width = F, position = "left")
```

### No Salary Data Set
```{r, No Salary Variables}

#Display the columns in each data set in a table format
as.data.frame(lapply(salaryData, class)) %>% t() %>% kable() %>% kable_styling(bootstrap_options = "striped", full_width = F, position = "left")
```

### Determining levels in some features
I'd like to better understand the levels and distribution of a few features in the data.
```{r Level Distributrion of Certain Features}
table(trainData$StandardHours) %>% kable() %>% kable_styling(bootstrap_options = "striped", full_width = F, position = "left")
table(trainData$EmployeeCount) %>% kable() %>% kable_styling(bootstrap_options = "striped", full_width = F, position = "left")
table(trainData$Over18) %>% kable() %>% kable_styling(bootstrap_options = "striped", full_width = F, position = "left")
```

### Cleaning the data sets
There exists some columns which do not appear to contain data that will be useful going forward.  This could be due to the column not containing data that can be grouped into identifiable levels, such as ID, StandardHours, Employee Count, Over18, and EmployeeNumber.  There are also a number of columns that appear to be pay rates, but do not appear to make sense or show consistency in relation to other columns that show, presumedly, like data.  These are HourlyRate, DailyRate, and MonthlyRate.  These rate data columns do not currently exist in the Salary Data set provided.

That work to remove them is done here.  
```{r, Clean Data}

#remove unneeded columns
removeVariables <- c("ID", "StandardHours", "EmployeeCount", "Over18", "EmployeeNumber", "HourlyRate", "DailyRate", "MonthlyRate")
trainData <- trainData[,!(names(trainData) %in% removeVariables)] 
#Don't remove ID from the two provided data sets
removeVariables <- c("StandardHours", "EmployeeCount", "Over18", "EmployeeNumber", "HourlyRate", "DailyRate", "MonthlyRate")
attritionData <- attritionData[,!(names(attritionData) %in% removeVariables)]
salaryData <- salaryData[,!(names(salaryData) %in% removeVariables)]
```

### Cleaning the data sets - Parts 2
In addition to the columns that we won't need, there exist columns which need some transformation.  Notably Age and DistanceFromHome.  These are currently continuous variables but will do better as ordinal variables using groups.  Additionally, I'll partition MonthlyIncome into categorical groups defined as AnnualIncome with breaks from < 40k (3333.33), 40K (3333.33) >= 70k (5833.33), 70k (5833.33) >= 100K (8333.33), and > 100k (8333.33)

We define those groups below.

After that, I will convert categorical variables to factors for use in models later.
```{r, Clean Data 2}
#Age
trainData$AgeGroup <- with(trainData, ifelse(Age < 21, "18-20", ifelse(Age < 31, "21-30", ifelse(Age < 41, "31-40", ifelse(Age < 51, "41-50", ifelse(Age<61, "51-60", "> 60"))))))
attritionData$AgeGroup <- with(attritionData, ifelse(Age < 21, "18-20", ifelse(Age < 31, "21-30", ifelse(Age < 41, "31-40", ifelse(Age < 51, "41-50", ifelse(Age<61, "51-60", "> 60"))))))
salaryData$AgeGroup <- with(salaryData, ifelse(Age < 21, "18-20", ifelse(Age < 31, "21-30", ifelse(Age < 41, "31-40", ifelse(Age < 51, "41-50", ifelse(Age<61, "51-60", "> 60"))))))
#DistanceFromHome
trainData$WorkDistance <- with(trainData, ifelse(DistanceFromHome < 5, "<5 Miles", ifelse(DistanceFromHome < 11, "5-10", ifelse(DistanceFromHome < 16, "11-15", ifelse(DistanceFromHome < 21, "16-20", ifelse(DistanceFromHome<26, "21-25", "> 25"))))))
attritionData$WorkDistance <- with(attritionData, ifelse(DistanceFromHome < 5, "<5 Miles", ifelse(DistanceFromHome < 11, "5-10", ifelse(DistanceFromHome < 16, "11-15", ifelse(DistanceFromHome < 21, "16-20", ifelse(DistanceFromHome<26, "21-25", "> 25"))))))
salaryData$WorkDistance <- with(salaryData, ifelse(DistanceFromHome < 5, "<5 Miles", ifelse(DistanceFromHome < 11, "5-10", ifelse(DistanceFromHome < 16, "11-15", ifelse(DistanceFromHome < 21, "16-20", ifelse(DistanceFromHome<26, "21-25", "> 25"))))))
#trainData$AnnualIncome <- with(trainData, ifelse(MonthlyIncome < 3333.33, "<40k", ifelse(MonthlyIncome < 5833.33, "40K-70K", ifelse(MonthlyIncome < 8333.33, "70k-100k", ">100k"))))
attritionData$AnnualIncome <- with(attritionData, ifelse(MonthlyIncome < 3333.33, "<40k", ifelse(MonthlyIncome < 5833.33, "40K-70K", ifelse(MonthlyIncome < 8333.33, "70k-100k", ">100k"))))
head(trainData)
#trainData[, c(2,3,4,7,9,12,14,17,26,27,28)] <- lapply(trainData[, c(2,3,4,7,9,12,14,17,26,27,28)], factor)
trainData <- trainData %>% mutate(across(where(is.character), as.factor))
attritionData <- attritionData %>% mutate(across(where(is.character), as.factor))
salaryData <- salaryData %>% mutate(across(where(is.character), as.factor))

```

### Review what we've done so far
```{r, Review}
head(trainData)
```

### Analysis of correlation seen among variables in the data
I'll look now at a correlation matrix to determine where correlation exists between variables in the data set.
```{r, Correlation Check}
#build correlation data using all numeric variables
corrData <- cor(trainData[,sapply(trainData, is.numeric)])
corrplot(corrData, type="upper", order="hclust",
         col=brewer.pal(n=8, name="RdYlBu"))
```

### Exploring those who left and those who didn't
I've seen the correlation data but what can I tell by looking at the mean values by whether or not an employee left Frito Lay?
```{r, Visualize the Data, warning=FALSE}
aggregate(trainData,by = list(trainData$Attrition),FUN = mean, na.rm=TRUE)  %>% kable() %>% kable_styling(bootstrap_options = "striped", full_width = F, position = "left") %>% scroll_box(height = 100, width = 800)
```

### Looking at the monthly income of those who left vs those who stayed
Is there anything remarkable about the income of those who left vs those who stayed?

``` {r, Comparing Income vs Attrition}
ggplot(data=trainData, aes(y=MonthlyIncome, x=Attrition, fill=Attrition)) + geom_boxplot() + labs(title="Plot of Monthly Income Vs. Attrition",x="Attrition", y = "Monthly Income") + scale_fill_manual(values=c("#CC1525", "#FBBD16"))
```

I see that the average age of an employee that left is about 4 years higher than one who did not leave during this period.  A leaving employee typically was higher paid, lived closer, had a higher education, and had longer experience in their role, with their current manager, and in the company.  That is all interesting but I'll need to test a few things to get a better idea of what is causing an employee to leave Frito Lay.  

### Determining splits by age group
I'd like to know how many employees exist in each age group among the training data set.  To do, I'll create a table showing the frequency of each age group.
```{r Age Groups}
table(trainData$AgeGroup) %>% kable() %>% kable_styling(bootstrap_options = "striped", full_width = F, position = "left")
```

The ages appear to be normally distributed across the typical working ages.

### Prepare to make predictions by removing highly correlated data points
Looking back to the correlation data, there are some points which feature high correlation and likely contribute to the data in the same way.  Some of these aren't surprising.  Take Performance Rating and Percent Salary Hike.  It seems logical to expect those with higher performance rating to earn the highest salary increases.  Also Total Working Years and Job Level.  You expect someone who has worked for a number of years to have a higher job role.  

To address these, I'm going to drop some variables from the data set.  I may change these values later but for now, will drop Years Since Last Promotion, as it is highly correlated to a number of other variables, Total Working Years, as Age Group can account for this data point adequately, and Percent Salary Hike as Performance Rating would appear to account for this in the set.
```{r, Drop Correlated Columns}
dropColumns <- c("YearsSinceLastPromotion", "TotalWorkingYears", "PercentSalaryHike")
trainData <- trainData[, !(names(trainData) %in% dropColumns)]
attritionData <- attritionData[, !(names(attritionData) %in% dropColumns)]
salaryData <- salaryData[, !(names(salaryData) %in% dropColumns)]
```
### Create training and test data sets from trainData
To properly train and test based on the trainData, I need to split that data set into a training set and a testing set.
``` {r, Split Set for Train and Test}
set.seed(1234)
splitPercentage <- createDataPartition(y= trainData$Attrition, p=.75, list = FALSE)
trainSet <- trainData[splitPercentage, ]
testSet <- trainData[-splitPercentage, ]
```

## Classification Prediction - Attrition

### Begin with a Naive Bayes Model to predict Attrition
I start out trying to predict the attrition data with a Naive Bayes Model.

### Helper Function to draw a confusion matrix
```{r, Draw Confusion Matrix Function}
#using example from https://stackoverflow.com/questions/23891140/r-how-to-visualize-confusion-matrix-using-the-caret-package/42940553

draw_confusion_matrix <- function(cm) {

  total <- sum(cm$table)
  res <- as.numeric(cm$table)

  # Generate color gradients. Palettes come from RColorBrewer.
  yellowPalette <- c("#FBBD16","#FFB955","#FFBA85","#FFC1B2")
  redPalette <- c("#CC1525","#FFBDE9","#FC85B2","#C14F7D")
  getColor <- function (yellowOrRed = "yellow", amount = 0) {
    if (amount == 0)
      return("#FFFFFF")
    palette <- yellowPalette
    if (yellowOrRed == "red")
      palette <- redPalette
    colorRampPalette(palette)(100)[10 + ceiling(90 * amount / total)]
  }

  # set the basic layout
  layout(matrix(c(1,1,2)))
  par(mar=c(2,2,2,2))
  plot(c(100, 345), c(300, 450), type = "n", xlab="", ylab="", xaxt='n', yaxt='n')
  title('CONFUSION MATRIX', cex.main=2)

  # create the matrix 
  classes = colnames(cm$table)
  rect(150, 430, 240, 370, col=getColor("yellow", res[1]))
  text(195, 435, classes[1], cex=1.2)
  rect(250, 430, 340, 370, col=getColor("red", res[3]))
  text(295, 435, classes[2], cex=1.2)
  text(125, 370, 'Predicted', cex=1.3, srt=90, font=2)
  text(245, 450, 'Actual', cex=1.3, font=2)
  rect(150, 305, 240, 365, col=getColor("red", res[2]))
  rect(250, 305, 340, 365, col=getColor("yellow", res[4]))
  text(140, 400, classes[1], cex=1.2, srt=90)
  text(140, 335, classes[2], cex=1.2, srt=90)

  # add in the cm results
  text(195, 400, res[1], cex=1.6, font=2, col='white')
  text(195, 335, res[2], cex=1.6, font=2, col='white')
  text(295, 400, res[3], cex=1.6, font=2, col='white')
  text(295, 335, res[4], cex=1.6, font=2, col='white')

  # add in the specifics 
  plot(c(100, 0), c(100, 0), type = "n", xlab="", ylab="", main = "DETAILS", xaxt='n', yaxt='n')
  text(10, 85, names(cm$byClass[1]), cex=1.2, font=2)
  text(10, 70, round(as.numeric(cm$byClass[1]), 3), cex=1.2)
  text(30, 85, names(cm$byClass[2]), cex=1.2, font=2)
  text(30, 70, round(as.numeric(cm$byClass[2]), 3), cex=1.2)
  text(50, 85, names(cm$byClass[5]), cex=1.2, font=2)
  text(50, 70, round(as.numeric(cm$byClass[5]), 3), cex=1.2)
  text(70, 85, names(cm$byClass[6]), cex=1.2, font=2)
  text(70, 70, round(as.numeric(cm$byClass[6]), 3), cex=1.2)
  text(90, 85, names(cm$byClass[7]), cex=1.2, font=2)
  text(90, 70, round(as.numeric(cm$byClass[7]), 3), cex=1.2)

  # add in the accuracy information 
  text(30, 35, names(cm$overall[1]), cex=1.5, font=2)
  text(30, 20, round(as.numeric(cm$overall[1]), 3), cex=1.4)
  text(70, 35, names(cm$overall[2]), cex=1.5, font=2)
  text(70, 20, round(as.numeric(cm$overall[2]), 3), cex=1.4)
}
```


```{r, Naive Bayes Attrition Prediction}
#set.seed(1234)
nbModel <- naiveBayes(Attrition ~ ., data=trainSet)

#predict with test
testSet$attritionPrediction <- predict(nbModel, testSet)
nbMatrix <- table(data = testSet$attritionPrediction, reference = testSet$Attrition)
#nbMatrix
cm <- confusionMatrix(nbMatrix)
#cm


draw_confusion_matrix(cm)
```

### Analyze results of Naive Bayes Model
You have asked for a 60/60 Sensitivity/Specificity model.  The Naive Bayes model returned a sensitivity of 83 % and a specificity of 45.7 %, which does not meet the requested levels.  This tells us that the Naive Bayes model is doing an ok job predicting when a person will stay with the employer but not that great at predicting when a person will leave employment.

I will proceed to see if I can do better and meet the goals of a 60/60 model as requested.

### Random Forest Model
I'll try using a random forest model to improve on the ability to predict attrition of employees.


```{r, Random Forest Model}
set.seed(1234)
rfModel <- train(Attrition~., data=trainSet, method="rf", metric="accuracy", trControl=trainControl(method="cv", number=5), tuneGrid=expand.grid(.mtry = c(1: 10)),nodesize=14, ntree=300, importance=TRUE)

#predict with test
testSet$rfPrediction <- predict(rfModel, testSet)
rfMatrix <- table(reference = testSet$Attrition, data = testSet$rfPrediction)
#head(rfPrediction)
#rfMatrix
cm <- confusionMatrix(rfMatrix)
#cm
draw_confusion_matrix(cm)
rfImportance <- varImp(rfModel)
head(rfImportance$importance, n=10)
```

### Analyze results of Random Forest Model
Using the random forest model, I am able to achieve a sensitivity of 86.3% and a specificity of 100% on the test data set, above the 60%/60% marker you specified. This improved upon the results of the naive bayes model from earlier and will be the model I propose you adopt for predicting attrition among your employees.

In analyzing which features contributed the most to an employee's decision to stay or leave, the top 10 were Age, Business Travel for those who traveled both frequently and rarely, Department for those in R&D and Sales, Distance from home that an employee lived, and the field of education which the employee had, including Life Sciences, Marketing, and Medical.


## Regression - Predicting salary of an employee

### Linear Regression Model

To begin with, I'll use a linear regression model and evaluate the features variance inflation factor to determine if any features should be eliminated from the dataset.

``` {r, Linear Regression of Salary}
lmModel <- lm(MonthlyIncome~., trainSet)
summary(lmModel)
VIF(lmModel)
```

A number of features show to be problematic, with a VIF over 5.  some are extraordinarily over a value of 5, such as JobRole at 634.23.  This would indicate that the linear model is having trouble estimating the coefficient for that variable.

Others that may be problematic would be Department, Distance From Home, Age Group, and Work Distance.  The last two were categorical variables created for the attrition prediction and will be removed.

In addition, it seems to fit a logic test that distance from home would not influence the salary of an employee.  Department could influence the salary but maybe not heavily across different departments, but more so within a department based on another feature.  I believe it will be best to remove it from consideration here.

Age does show a higher than 10 VIF, however, I do believe that Age will be a valuable feature in predicting salary, so I will leave it for now.

There are other factors which I am not comfortable leaving in the dataset are Attrition, as whether an employee left could imply their satisfaction with their salary but doesn't indicate they're salary properly.

``` {r, Prep data for Linear Model}
removeVariables <- c("JobRole", "Department", "DistanceFromHome", "AgeGroup", "WorkDistance", "Attrition")
trainSetLM2 <- trainSet[,!(names(trainSet) %in% removeVariables)] 
testSetLM2 <- testSet[,!(names(testSet) %in% removeVariables)] 
```

### Rerun the regression analysis of the linear model

``` {r, Linear Regression of Salary Run 2}
lmModel <- lm(MonthlyIncome~., trainSetLM2)
summary(lmModel)
VIF(lmModel)
```

The Linear Regression resulted in an RMSE of $1379 and an adjusted R Squared of 0.9064.

### Can another model improve on the results seen with Linear Regression

I will begin using the full dataset containing all of the predictors that were eliminated in the Linear Regression modeling.
```{r, Model built using Cubist Package in r}
set.seed(1234)
cubistModel <- cubist(x= trainSet[, !(names(trainSet) %in% c("MonthlyIncome"))], y=trainSet$MonthlyIncome, committees = 5)
cubistModel
summary(cubistModel)
modelPrediction <- predict(cubistModel, testSet[, !(names(testSet) %in% c("MonthlyIncome"))])
#RMSE
cubistRMSE <- sqrt(mean((modelPrediction - testSet$MonthlyIncome)^2))
cubistRMSE
cubistR2 <- cor(modelPrediction, testSet$MonthlyIncome)^2
cubistR2
```

### Evaluating Cubist Model

With an RMSE of $1296 and an R^2 of 0.9295, there is improvement in the model over the linear regression.  Now I'll attempt to tune for better predictors to see if I can improve it more.

```{r, Check Cubist Model}
varImp(cubistModel)
```

### Applying the results from the evaluation of the model

Now I will try to apply model tuning using the caret package to use a 10 fold cross validation over the parameters Committees and Neighbors.

``` {r, 10 Fold CV Cubist Tuning}
grid <- expand.grid(committees = c(10, 15, 20, 25, 30, 35, 40, 45, 50), neighbors = c(0, 1, 3, 5))
set.seed(1234)
caretGrid <- train(x= trainSet[, !(names(trainSet) %in% c("MonthlyIncome"))], y=trainSet$MonthlyIncome, method="cubist", tuneGrid=grid, trControl = trainControl(method="cv"))
caretGrid
ggplot(caretGrid)
```

### Best model from Cubist tuning

Using the CARET package to tune the model with a set of committee and neighbor selections, I was able to find a best fit with 15 committees and no neighbors.  In that best fit instance, I was able to achieve an RMSE of 1024.255 and an R Squared of 0.9473.

I'll now run this best fit model against the test data to confirm like results.

```{r, Run the best fit model against the test}
modelPrediction <- predict(caretGrid, testSet[, !(names(testSet) %in% c("MonthlyIncome"))])
#RMSE
cubistRMSE <- sqrt(mean((modelPrediction - testSet$MonthlyIncome)^2))
cubistRMSE
cubistR2 <- cor(modelPrediction, testSet$MonthlyIncome)^2
cubistR2
```

### Analyzing the results of running against the test sample

I was able to achieve results of an RMSE of 1197.722 and an R^2 of 0.9396, which shows that the model is slightly over fit to the training data set but does still return better results than simply a linear regression model.

### Generating result sets on the Attrition and Salary missing data sets

I'll now generate the predicted values from the data sets with the missing data so to allow you to validate my models and methodologies, using my highest performing models.

``` {r, Generate predicted values to missing data sets}
attritionData$PredictedValue <- predict(rfModel, attritionData)
salaryData$PredictedValue <- predict(caretGrid, salaryData)

attritionExport <- attritionData %>% select(c("ID", "PredictedValue"))
write.csv(attritionExport, "Case2PredictionsMcDonald Attrition.csv")

salaryExport <- salaryData %>% select(c("ID", "PredictedValue"))
write.csv(salaryExport, "Case2PredictionsMcDonald Salary.csv")
```
